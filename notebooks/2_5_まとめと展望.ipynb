{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.5 まとめと展望"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "本章では、まずモデルの複雑さについて議論し、次に**汎化**について議論した。汎化とは新しい見たことのないデータに対してうまく機能するようにモデルを学習することだ。この汎化という考え方から、訓練データに現れている変異をモデルがとらえきれていない状態を表す適合不足という概念と、逆に訓練データに適合しすぎてしまい、新しいデータに汎化できない状態を表す過剰適合という概念に至った。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "次に、クラス分類と回帰を行うさまざまな機械学習モデルについて、それらの利点と欠点、モデルの複雑さを制御する方法を述べた。多くのアルゴリズムでは、性能を得るためには正しいパラメータを選択することが重要だということを説明した。また、アルゴリズムによって、入力データの表現、特に特徴量のスケールに敏感であることも示した。したがって、モデルがおいている仮定やパラメータの意味を理解せずに、適当なデータセットに適当なアルゴリズムを適用するだけでは正確なモデルを得ることはできない。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "本章にはさまざまなアルゴリズムに関する情報が大量に含まれている。以降の章を読むうえで、本章の内容すべてを詳細に覚えておく必要はないが、本章で述べたモデルに関する知識と、どのようなときにどのアルゴリズムを使うべきかは、実際に機械学習を利用する上で重要である。それぞれのモデルを簡単にまとめておこう。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 最近傍法\n",
    "- 小さいデータに関してはよいデータベースラインとなる。説明が容易。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 線形モデル\n",
    "- 最初に試してみるべきアルゴリズム。非常に大きいデータセットに適する。非常に高次元のデータに適する。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### ナイーブベイズ\n",
    "- クラス分類にしか使えない。線形モデルよりもさらに高速。非常鬼大きいデータセット、高次元データに適する。線形モデルよりも制度が劣ることが多い。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 決定木\n",
    "- 非常に高速。データのスケールを考慮する必要がない。可視化が可能で説明しやすい。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### ランダムフォレスト\n",
    "- ほとんどの場合単一の決定木よりも高速で、頑健で、強力。データのスケールを考慮する必要がない。高次元の疎なデータには適さない。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 勾配ブースティング決定木\n",
    "- 多くの場合ランダムフォレストよりも少し制度が高い。ランダムフォレストよりも訓練に時間がかかるが、予測はこちらの方が早く、メモリ使用量も小さい。ランダムフォレストよりもパラメータに敏感。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### サポートベクタマシン\n",
    "- 同じような意味を持つ特徴量からなる中規模なデータセットに対しては強力。データのスケールを調整する必要がある。パラメータに敏感。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### ニューラルネットワーク\n",
    "- 非常に複雑なモデルを構築できる。特に大きなデータセットに有効。データのスケールを調整する必要がある。パラメータに敏感。大きいモデルは訓練に時間がかかる。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "新しいデータセットを扱う場合は、線形モデルやナイーブベイズや最近傍法などの、簡単なモデルでどのくらい精度が得られるか試すべきだ。データをより深く理解できたら、ランダムフォレストや勾配ブースティング、SVM、ニューラルネットワークなどの、より複雑なモデルに移行することを考えるとよいだろう。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ここまで読めば、これまで述べたモデルについて、利用し、パラメータをチューニングし、解析する方法が大体わかったことと思う。本章では、主に２クラス分類を取り扱ったが、これは理解が容易だからだ。ここで述べたアルゴリズムのほとんどが、クラス分類にも回帰にも利用できるし、クラス分類のアルゴリズムは多クラス分類をサポートしている。scikit-learnに組み込まれているデータセットに対して、アルゴリズムを適用してみよう。回帰にはboston_housingやdiabetesデータセットが、多クラス分類にはdigitsデータセットがよいだろう。さまざまなデータセットに対して、さまざまなアルゴリズムを適用してみれば、モデルの解析が簡単か、データの表現に対して敏感かがわかるだろう。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "これまでに、それぞれのアルゴリズムに対するパラメータ設定の￥影響を解析してきたが、実運用環境で新しいデータに対して実際にうまく汎化できるモデルを作るのはさらに面倒だ。パラメータを適切に調整する方法と、自動的に良いパラメータを発見する方法については「**６章　アルゴリズムチェーンとパイプライン**」で説明する。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "しかしその前に、次の章で教師なし学習と前処理について詳しく見ていこう。"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
